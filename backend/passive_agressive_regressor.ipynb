{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor, PassiveAggressiveRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 1000000\n",
    "sliding_window_data = pd.read_csv(\"sliding_window_data.csv\", chunksize=chunksize, iterator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Seed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3101\n",
    "np.random.seed(3101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data = train_test_split(sliding_window_data, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding_window_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"date\",\"time\",\"station\"]\n",
    "for i in range(1,7):\n",
    "    for j in range(1,7):\n",
    "        drop_cols.append(f\"T{i}S{j}_station number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [20:31, 47.35s/it]\n"
     ]
    }
   ],
   "source": [
    "regression_model = PassiveAggressiveRegressor(random_state=seed, shuffle=True)\n",
    "for batch in tqdm(sliding_window_data):\n",
    "    drop_cols = [\"date\",\"time\",\"station\"]\n",
    "    for i in range(1,7):\n",
    "        for j in range(1,7):\n",
    "            drop_cols.append(f\"T{i}S{j}_station number\")\n",
    "    batch.drop(drop_cols, axis=1, inplace=True)\n",
    "    batch.fillna(value=0, inplace=True)\n",
    "    regression_model.partial_fit(batch.iloc[:,1:], batch.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_skips = np.random.randint(1,chunksize,size=3101)\n",
    "test_data = pd.read_csv(\"sliding_window_data.csv\", header=0, nrows=chunksize, skiprows=random_skips)\n",
    "drop_cols = [\"date\",\"time\",\"station\"]\n",
    "for i in range(1,7):\n",
    "    for j in range(1,7):\n",
    "        drop_cols.append(f\"T{i}S{j}_station number\")\n",
    "test_data.drop(drop_cols, axis=1, inplace=True)\n",
    "test_data.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = regression_model.predict(test_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(y_pred,y_true):\n",
    "    print(f'R2 score is : {sm.r2_score(y_true,y_pred)}')\n",
    "    print(f'MAE is : {sm.mean_absolute_error(y_true,y_pred)}')\n",
    "    print(f'MSE is : {sm.mean_squared_error(y_true,y_pred)}')\n",
    "    \n",
    "    threshold = 0.0\n",
    "    temp = pd.concat([pd.DataFrame(prediction, columns=[\"predict\"]),y_true], axis=1)\n",
    "    temp[\"predict\"].round(decimals=1)\n",
    "    fn = temp[temp[\"value\"] > threshold]\n",
    "    fn = fn[fn[\"predict\"] <= threshold ]\n",
    "    p = y_true[y_true > threshold]\n",
    "    fnr = len(fn)/len(p)\n",
    "    recall = 1-fnr\n",
    "    print(f'Recall is : {recall}')\n",
    "    print(f'False negative rate is : {fnr}')\n",
    "\n",
    "    tn = temp[temp[\"value\"] <= threshold]\n",
    "    tn = tn[tn[\"predict\"] <= threshold ]\n",
    "    fp = temp[temp[\"value\"] <= threshold]\n",
    "    fp = fp[fp[\"predict\"] > threshold]\n",
    "    fpr = len(tn)/(len(tn) + len(fp))\n",
    "    print(f'False positive rate (FP/FP+TN) is : {fpr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score is : 0.04567825538857406\n",
      "MAE is : 0.02756740022214615\n",
      "MSE is : 0.06639239202286325\n",
      "Recall is : 0.6643808707453838\n",
      "False negative rate is : 0.33561912925461623\n",
      "False positive rate (FP/FP+TN) is : 0.9459054054471138\n"
     ]
    }
   ],
   "source": [
    "display_metrics(prediction,test_data.iloc[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
